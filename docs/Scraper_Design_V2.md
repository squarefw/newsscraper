### **网站内容自动抓取器 - 分析与设计文档 (V3)**

#### 1. 项目目标

构建一个功能强大,高度可配置的自动化内容抓取服务. 该服务能够从任意指定网站抓取包括文本,图片,视频在内的多媒体新闻内容,利用可配置的关键词对内容进行筛选,通过可插拔的 AI 引擎对内容进行智能处理和优化,最终将成品数据推送到指定的新闻系统 API. 整个服务将被容器化,以便于快速,可靠地部署和扩展.

#### 2. 核心功能需求 (细化)

*   **AI 驱动的搜索与内容发现**:
    *   **目标**: 自动化地在目标网站上发现相关新闻内容.
    *   **细节**: 
        1.  **AI 关键词搜索**: 系统可配置使用 AI (通过 AI 引擎) 根据预设关键词在目标网站的搜索功能中执行搜索. AI 将生成搜索查询并识别搜索结果页面.
        2.  **搜索结果解析**: 从搜索结果页面中提取每个新闻条目的链接.
        3.  **动态 URL 发现**: 即使没有预设的 `articleSelector`, AI 也能通过分析页面内容和结构,识别出潜在的新闻文章链接.

*   **高级内容提取 (AI 辅助)**:
    *   **目标**: 从复杂或结构多变的网页中精准提取结构化数据.
    *   **细节**: 
        1.  **AI 辅助内容识别**: 除了传统的 CSS 选择器, 系统可配置使用 AI 引擎来分析单个新闻页面的内容, 智能识别并提取文章的 **标题, 正文, 分类, 标签**, 以及内嵌的 **所有图片链接** 和 **视频嵌入代码(iframe/video-src)**. 这将提高对网站结构变化的适应性.
        2.  **多媒体内容提取**: 确保能够从文章正文中提取所有图片 URL 和视频嵌入代码.

*   **关键词筛选**:
    *   **目标**: 只处理与业务相关的新闻.
    *   **细节**: 系统需要根据一个可配置的关键词列表,对抓取到的文章标题或内容进行匹配. 只有包含至少一个关键词的文章才会被送入后续流程.

*   **AI 内容优化 (可插拔)**:
    *   **目标**: 提升抓取内容的质量和独创性.
    *   **细节**:
        *   支持对接不同的 AI 引擎 (例如: Gemini, OpenAI GPT 系列, 硅基流动, OpenRouter 或其他第三方/自建模型 API).
        *   AI 引擎本身及其 API Key/Endpoint 必须是可配置的.
        *   可配置 AI 处理任务, 例如:
            *   **内容重写或润色**: 提升文章可读性和原创性.
            *   **内容摘要**: 生成文章核心内容的简短摘要.
            *   **关键词/标签生成**: 自动为文章生成合适的标签.
        *   可以选择关闭 AI 处理流程.

*   **内容去重**:
    *   **目标**: 避免重复存储相同的新闻内容.
    *   **细节**: 在将新闻推送到 API 之前, 系统将对新闻内容进行去重检查. 可以基于文章标题的哈希值, 或内容的相似度进行判断. 考虑使用 Redis 等缓存机制存储已处理文章的指纹.

*   **可配置的数据推送**:
    *   **目标**: 将处理好的数据存入主系统.
    *   **细节**: 用于接收新闻数据的服务器 API 地址和认证凭证(如 API Key)必须是可配置的, 不能硬编码.

*   **自动化与调度**:
    *   **目标**: 无人值守,自动运行.
    *   **细节**: 能够为每个抓取目标网站独立配置抓取周期 (例如, 每 10 分钟, 每小时, 每天特定时间).

*   **Docker 化部署**:
    *   **目标**: 实现标准化,跨环境的部署.
    *   **细节**: 项目必须包含一个 `Dockerfile`, 用于将整个应用程序及其依赖打包成一个独立的 Docker 镜像. 镜像应能通过环境变量进行配置.

*   **日志与监控**:
    *   **目标**: 保证系统的可维护性.
    *   **细节**: 详细记录任务执行日志,包括: 任务启动, 成功抓取数, 筛选掉的文章, AI 处理结果, API 推送成功/失败等.

#### 3. 拟议架构与技术选型

*   **项目结构**:
    *   `newsscraper/`
        *   `src/`
            *   `main.ts`: 程序主入口, 负责加载配置, 启动调度器.
            *   `scheduler.ts`: 任务调度器 (`node-cron`), 根据配置定时触发任务.
            *   `searcher.ts`: **新增模块, 负责 AI 驱动的网站搜索和链接发现.**
            *   `scraper.ts`: 核心抓取器 (`axios` + `cheerio`), 负责获取和解析 HTML, 提取多媒体内容. **将增强 AI 辅助提取能力.**
            *   `filter.ts`: 关键词过滤器, 检查文章是否符合要求.
            *   `deduplicator.ts`: **新增模块, 负责新闻内容去重.**
            *   `ai/`: AI 处理模块 (可插拔架构)
                *   `base.ts`: 定义 AI 引擎的统一接口 (Interface).
                *   `gemini.ts`: Gemini 引擎的实现.
                *   `openai.ts`: OpenAI 引擎的实现.
                *   `siliconflow.ts`: 硅基流动 AI 引擎的实现.
                *   `openrouter.ts`: OpenRouter AI 引擎的实现.
                *   `factory.ts`: AI 引擎工厂, 根据配置选择使用哪个引擎.
            *   `apiClient.ts`: 负责将最终数据推送到目标服务器 API.
            *   `logger.ts`: 日志模块 (`winston`).
        *   `config/`
            *   `config.development.json`: 开发环境配置 (API 地址, AI Keys, 关键词等).
            *   `config.production.json`: 生产环境配置.
            *   `targets.json`: 定义抓取目标网站及 CSS 选择器规则. **将增加 AI 搜索相关配置.**
        *   `Dockerfile`: Docker 镜像配置文件.
        *   `package.json`
        *   `tsconfig.json`

*   **技术选型**:
    *   **核心**: Node.js, TypeScript
    *   **HTML 抓取/解析**: `axios`, `cheerio`
    *   **任务调度**: `node-cron`
    *   **日志**: `winston`
    *   **配置管理**: `dotenv` (用于从 `.env` 文件加载环境变量, 方便 Docker 部署时注入配置)
    *   **容器化**: Docker
    *   **去重**: 可能需要 `crypto` (Node.js 内置) 进行哈希, 或集成 `ioredis` 等 Redis 客户端库进行分布式去重.

#### 4. 数据处理流程

1.  **启动**: `main.ts` 加载环境变量和配置文件 (`config.*.json`, `targets.json`).
2.  **调度**: `scheduler.ts` 为 `targets.json` 中的每个目标创建一个定时任务.
3.  **触发**: 定时器触发, 开始执行特定目标的抓取任务.
4.  **内容发现 (AI 辅助或传统)**:
    *   **如果配置了 AI 搜索**: `searcher.ts` 将使用 AI 引擎根据关键词在目标网站上执行搜索, 并从搜索结果中提取新闻文章的 URL 列表.
    *   **如果未配置 AI 搜索**: `scraper.ts` 将直接从 `targets.json` 中定义的 `url` 开始抓取, 并使用 `articleSelector` 提取文章链接.
5.  **抓取与初步提取**: `scraper.ts` 遍历发现的每个文章 URL, 请求页面, 获取 HTML.
6.  **AI 辅助内容提取**: `scraper.ts` 可选择性地调用 AI 引擎, 分析 HTML 内容, 智能识别并提取文章的 **标题, 正文, 分类, 标签, 作者, 发布日期**, 以及内嵌的 **所有图片链接** 和 **视频嵌入代码**.
7.  **关键词筛选**: `filter.ts` 检查提取出的标题和内容是否包含 `config.json` 中定义的关键词.
    *   **若不包含**: 记录日志, 任务结束.
    *   **若包含**: 进入下一步.
8.  **内容去重**: `deduplicator.ts` 对文章进行去重检查. 如果文章已存在, 则记录日志并跳过.
9.  **AI 处理**: 
    *   `ai/factory.ts` 根据 `config.json` 中的配置, 初始化对应的 AI 引擎.
    *   调用 AI 引擎, 将提取出的内容(如正文)发送过去, 执行配置好的优化任务(如重写, 摘要, 标签生成).
    *   接收 AI 返回的处理结果.
10. **推送**: `apiClient.ts` 将原始数据和 AI 处理结果整合, 构造成符合目标 API 规范的数据包.
11. **存储**: `apiClient.ts` 调用 `config.json` 中配置的服务器 API 地址, 发送 POST 请求, 将数据存入主项目数据库.
12. **日志**: 在流程的每一步, 都通过 `logger.ts` 记录详细的执行日志.

#### 5. Dockerization 方案

*   **基础镜像**: 使用轻量级的 `node:18-alpine` 来减小镜像体积.
*   **多阶段构建**:
    1.  **Build Stage**: 拷贝 `package.json`, 安装所有依赖(包括 devDependencies), 拷贝源代码, 编译 TypeScript (`tsc`).
    2.  **Production Stage**: 再次使用 `node:18-alpine`, 只从 Build Stage 拷贝编译后的 `dist` 目录, `node_modules`, 和 `package.json`. 这样最终的生产镜像不包含 TS 源码和开发依赖, 体积更小, 更安全.
*   **配置**:
    *   `Dockerfile` 中使用 `ENV` 指令设置 `NODE_ENV=production`.
    *   通过 Docker 的 `-e` 标志或 `docker-compose.yml` 的 `environment` 字段, 在启动容器时注入所有敏感配置(API 地址, 密钥, 关键词等)作为环境变量. 应用程序通过 `process.env` 读取这些配置.
    *   `targets.json` 可以作为配置文件挂载到容器中, 方便修改抓取目标而无需重建镜像.
*   **启动命令**: `CMD ["node", "dist/main.js"]`